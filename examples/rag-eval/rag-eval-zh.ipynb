{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG 应用评估\n",
    "\n",
    "RAG 应用评估是一个复杂的问题，完整的评估有很多指标。\n",
    "\n",
    "## 1. 相关开源项目\n",
    "\n",
    "### 1.1 [ragas](https://github.com/explodinggradients/ragas)\n",
    "\n",
    "开源框架 ragas 有如下指标。\n",
    "\n",
    "| 阶段 | 指标名称 | 指标描述 | 评估方法 | 是否需要参考答案(`ground truth`) |\n",
    "| --- | --- | --- | --- | --- | \n",
    "| 检索 | 上下文召回 Context Recall | 检索到的上下文`context`与参考答案`ground truth`的一致性程度 | LLM | 是 |\n",
    "| 检索 | 上下文精确度 Context Precision | 评估检索到的上下文`context`中，和参考答案`ground truth`一致的结果是否靠前 | LLM | 是 |\n",
    "| 检索 | 上下文相关性 Context Relevancy | 评估检索到的上下文`context`中，和问题`question`的相关程度 | LLM | 否 |\n",
    "| 生成 | 回答相关性 Answer Relevancy | 问题`question` 和答案 `answer`的相关性 | LLM | 否 |\n",
    "| 生成 | 回答语义相似性 Answer semantic similarity | 答案 `answer`和参考答案`ground truth`的语义相似度 | 交叉编码器 | 是 |\n",
    "| 生成 | 回答正确性 Answer Correctness | 答案 `answer`和参考答案`ground truth` 在事实方面的一致性 | LLM | 是 |\n",
    "| 生成 | 回答忠诚度 Answer Faithfulness | 答案 `answer` 和上下文 `context`的事实一致性 | LLM | 否 |\n",
    "| 生成 | 回答批评 Answer Critique | 对答案 `answer` 在指定的 Prompt 进行批评以识别有害内容 | LLM | 否 |\n",
    "\n",
    "当数据集中没有人工标注的参考答案时，就需要使用那些不需要参考答案的指标，例如上下文相关性、回答相关性、回答忠诚度、回答批评等。\n",
    "\n",
    "如果觉得评估指标过多，在有参考答案时，建议选择如下两个指标：\n",
    "\n",
    "1. 上下文召回：用来评估检索效果。注意这里如果效果下降，可能原因是检索本身的效果不好，也可能是数据源缺少相关的数据。\n",
    "2. 回答正确性：用来评估生成效果。\n",
    "\n",
    "注：开源框架 ragas 中的 Prompt 和交叉编码器都是英文，不适合中文环境。\n",
    "\n",
    "### 1.2 [tvalmetrics](https://github.com/TonicAI/tvalmetrics)\n",
    "\n",
    "| Metric Name              | Inputs                                                    | Formula | What does it measure? | Which components does it evaluate? |\n",
    "| ----------------------- | --------------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------ |----|\n",
    "| **Answer similarity score** | Question + Reference answer + LLM answer | Score between 0 and 5 | How well the reference answer matches the LLM answer. | All components.                     |\n",
    "| **Retrieval precision** | Question + Retrieved context                         | (Count of relevant retrieved context) / (Count of retrieved context) | Whether the context retrieved is relevant to answer the given question. | Chunker + Embedder + Retriever    |\n",
    "| **Augmentation precision** | Question + Retrieved context + LLM answer             | (Count of relevant retrieved context in LLM answer) / (Count of relevant retrieved context) | Whether the relevant context is in the LLM answer. | Prompt builder + LLM                |\n",
    "| **Augmentation accuracy** | Retrieved context + LLM answer                          | (Count of retrieved context in LLM answer) / (Count of retrieved context) | Whether all the context is in the LLM answer. | Prompt builder + LLM                |\n",
    "| **Answer consistency** or **Answer consistency binary** | Retrieved context + LLM answer                          | (Count of the main points in the answer that can be attributed to context) / (Count of main points in answer) | Whether there is information in the LLM answer that does not come from the context. | Prompt builder + LLM                |\n",
    "| **Retrieval k-recall** | Question + Retrieved context + Top k context         | (Count of relevant retrieved context) / (Count of relevant context in top k context) | How well the retrieval system retrieves all of the relevant context. | Chunker + Embedder + Retriever    |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 数据集准备\n",
    "\n",
    "评测 RAG 应用，数据集必须有：\n",
    "\n",
    "- 运行输入：\n",
    "    - question[str]：问题\n",
    "- 运行输出\n",
    "    - answer[str]：RAG 应用给出的回答\n",
    "    - contexts[list[str]]: 检索到的上下文，顺序则代表相似度。\n",
    "- 评估输入\n",
    "    - reference_context[str]: 参考上下文，用于评估检索的正确性。\n",
    "    - reference_answer[str]: 参考答案，用于评估回答的正确性。\n",
    "\n",
    "数据集有三种方法准备：\n",
    "\n",
    "1. 使用开源数据集，比如 ragas 引用的 explodinggradients/fiqa 数据集。但是中文的 RAG 数据集较少。而且开源数据集只能代表 RAG 的通用能力，不能代表 RAG 在特定领域的能力。\n",
    "2. 人工标注，这种方法需要大量的人力成本，但是可以标注特定领域的数据集。\n",
    "3. 使用 LLM 自动抽取 QA 对，从而形成数据集。这种方法的优点是成本低，缺点是数据集的质量可能不高。自动标注尽量使用能力较强的 LLM，比如 GPT-4 等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 使用开源数据集\n",
    "\n",
    "从项目 [m3e-base](https://huggingface.co/moka-ai/m3e-base) 介绍中，可以看到作者收集的众多用来训练 Embedding 模型的中文数据集，从其中挑选问答类数据集处理后可用于 RAG 评估。\n",
    "\n",
    "筛选后，[dureader_robust](https://huggingface.co/datasets/PaddlePaddle/dureader_robust/viewer/plain_text/train?row=96) 和 [cmrc2018](https://huggingface.co/datasets/cmrc2018) 比较适合用于 RAG 评估。前者的回答过于简略，所以我们选择 cmrc2018 数据集进行评估。\n",
    "\n",
    "注意：cmrc2018 数据集并没有允许商用，请不要在商业项目中使用。\n",
    "\n",
    "#### 2.1.1 cmrc 数据集下载和转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'TRIAL_800_QUERY_0', 'context': '基于《跑跑卡丁车》与《泡泡堂》上所开发的游戏，由韩国Nexon开发与发行。中国大陆由盛大游戏运营，这是Nexon时隔6年再次授予盛大网络其游戏运营权。台湾由游戏橘子运营。玩家以水枪、小枪、锤子或是水炸弹泡封敌人(玩家或NPC)，即为一泡封，将水泡击破为一踢爆。若水泡未在时间内踢爆，则会从水泡中释放或被队友救援(即为一救援)。每次泡封会减少生命数，生命数耗完即算为踢爆。重生者在一定时间内为无敌状态，以踢爆数计分较多者获胜，规则因模式而有差异。以2V2、4V4随机配对的方式，玩家可依胜场数爬牌位(依序为原石、铜牌、银牌、金牌、白金、钻石、大师) ，可选择经典、热血、狙击等模式进行游戏。若游戏中离，则4分钟内不得进行配对(每次中离+4分钟)。开放时间为暑假或寒假期间内不定期开放，8人经典模式随机配对，采计分方式，活动时间内分数越多，终了时可依该名次获得奖励。', 'question': '生命数耗完即算为什么？', 'answers': {'text': ['踢爆'], 'answer_start': [127]}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'context', 'question', 'answers'],\n",
       "        num_rows: 10142\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'context', 'question', 'answers'],\n",
       "        num_rows: 3219\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'context', 'question', 'answers'],\n",
       "        num_rows: 1002\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "cmrc = load_dataset(\"cmrc2018\")\n",
    "print(cmrc[\"test\"][0])\n",
    "cmrc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正式项目中，应该以全部的数据作为我们的向量索引的基础数据，单条数据格式如上。我们挑选其中的 context 嵌入到向量索引中。\n",
    "\n",
    "本次我们就只以 test 的 1000 条数据建立索引。同时以 test 的随机 50 条查询作为验证数据集。\n",
    "\n",
    "此时我们可以准备两种数据集\n",
    "\n",
    "1. 用于运行的数据集，即只有 question / reference_answer / reference_contexts 的数据集。\n",
    "2. 用于评估的数据集，即使用 chain 检索后的数据集，包含全部数据。\n",
    "\n",
    "前者在启动评估任务的时候还要注册 Provider 用于 RAG 生成，为模拟真实的情况，我们选择 1。那么此处只需要生成用于运行的数据集即可。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>reference_context</th>\n",
       "      <th>reference_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>与藤原纪香的婚礼耗资多少日圆？</td>\n",
       "      <td>阵内智则（1974年2月22日－），日本喜剧演员及主持。曾经于日本节目《娱乐之神》表演多场短...</td>\n",
       "      <td>5亿日圆</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>此剧的制作人是谁？</td>\n",
       "      <td>《西南忠魂》是台湾台湾电视公司于1984年（民国73年）3月28日至1985年（民国74年）...</td>\n",
       "      <td>制作人伍宗德</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>达曼的卫星城有哪几座？</td>\n",
       "      <td>达曼（）位于沙特阿拉伯的东部省，是沙特石油工业的重要中心。达曼是东部省最大的城市，达曼港也是...</td>\n",
       "      <td>达曼的卫星城有现代经济中心 Khobar、世界最大的沙特Aramco石油公司所在地札哈兰以及...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>《This Is Where I Came In》是Bee Gees的第几张原创专辑？</td>\n",
       "      <td>《This Is Where I Came In》是Bee Gees的第20张原创专辑，也是...</td>\n",
       "      <td>第20张</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>卡洛身兼几家骑士团的大团长职位？</td>\n",
       "      <td>卡洛·玛利亚·贝尔纳多·真纳罗（Carlo Maria Bernardo Gennaro，）...</td>\n",
       "      <td>圣乔治康斯坦丁骑士团、圣斐迪南骑士团、圣真纳罗骑士团和弗朗切斯科一世王家骑士团</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      question  \\\n",
       "0                              与藤原纪香的婚礼耗资多少日圆？   \n",
       "1                                    此剧的制作人是谁？   \n",
       "2                                  达曼的卫星城有哪几座？   \n",
       "3  《This Is Where I Came In》是Bee Gees的第几张原创专辑？   \n",
       "4                             卡洛身兼几家骑士团的大团长职位？   \n",
       "\n",
       "                                   reference_context  \\\n",
       "0  阵内智则（1974年2月22日－），日本喜剧演员及主持。曾经于日本节目《娱乐之神》表演多场短...   \n",
       "1  《西南忠魂》是台湾台湾电视公司于1984年（民国73年）3月28日至1985年（民国74年）...   \n",
       "2  达曼（）位于沙特阿拉伯的东部省，是沙特石油工业的重要中心。达曼是东部省最大的城市，达曼港也是...   \n",
       "3  《This Is Where I Came In》是Bee Gees的第20张原创专辑，也是...   \n",
       "4  卡洛·玛利亚·贝尔纳多·真纳罗（Carlo Maria Bernardo Gennaro，）...   \n",
       "\n",
       "                                    reference_answer  \n",
       "0                                               5亿日圆  \n",
       "1                                             制作人伍宗德  \n",
       "2  达曼的卫星城有现代经济中心 Khobar、世界最大的沙特Aramco石油公司所在地札哈兰以及...  \n",
       "3                                               第20张  \n",
       "4            圣乔治康斯坦丁骑士团、圣斐迪南骑士团、圣真纳罗骑士团和弗朗切斯科一世王家骑士团  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = []\n",
    "for i in cmrc[\"test\"].shuffle(seed=42).select(range(100)):\n",
    "    test_data.append({\n",
    "        \"question\": i[\"question\"],\n",
    "        \"reference_context\": i[\"context\"],\n",
    "        \"reference_answer\": i[\"answers\"][\"text\"][0],\n",
    "    })\n",
    "import pandas as pd\n",
    "pd.DataFrame(test_data).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"cmrc-eval-zh.jsonl\", \"w\") as f:\n",
    "    for i in test_data:\n",
    "        f.write(json.dumps(i, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 生成 FAISS 向量检索嵌入\n",
    "\n",
    "Embedding 模型我们使用目前 cmteb reranking 任务 SOTA 的模型：[stella-base-zh](https://huggingface.co/infgrad/stella-base-zh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/yangtao04/Library/Application Support/hatch/env/virtual/langeval-cli/4fLtKDhF/langeval-cli/lib/python3.11/site-packages (0.0.330)\n",
      "Requirement already satisfied: openai in /Users/yangtao04/Library/Application Support/hatch/env/virtual/langeval-cli/4fLtKDhF/langeval-cli/lib/python3.11/site-packages (0.28.1)\n",
      "Requirement already satisfied: faiss-cpu in /Users/yangtao04/Library/Application Support/hatch/env/virtual/langeval-cli/4fLtKDhF/langeval-cli/lib/python3.11/site-packages (1.7.4)\n",
      "Requirement already satisfied: tiktoken in /Users/yangtao04/Library/Application Support/hatch/env/virtual/langeval-cli/4fLtKDhF/langeval-cli/lib/python3.11/site-packages (0.5.1)\n",
      "Collecting sentence_transformers\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m218.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /Users/yangtao04/Library/Application Support/hatch/env/virtual/langeval-cli/4fLtKDhF/langeval-cli/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/yangtao04/Library/Application Support/hatch/env/virtual/langeval-cli/4fLtKDhF/langeval-cli/lib/python3.11/site-packages (from langchain) (2.0.23)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/yangtao04/Library/Application Support/hatch/env/virtual/langeval-cli/4fLtKDhF/langeval-cli/lib/python3.11/site-packages (from langchain) (3.8.6)\n",
      "Requirement already satisfied: anyio<4.0 in /Users/yangtao04/Library/Application Support/hatch/env/virtual/langeval-cli/4fLtKDhF/langeval-cli/lib/python3.11/site-packages (from langchain) (3.7.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/yangtao04/Library/Application Support/hatch/env/virtual/langeval-cli/4fLtKDhF/langeval-cli/lib/python3.11/site-packages (from langchain) (0.6.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/yangtao04/Library/Application Support/hatch/env/virtual/langeval-cli/4fLtKDhF/langeval-cli/lib/python3.11/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.52 in /Users/yangtao04/Library/Application Support/hatch/env/virtual/langeval-cli/4fLtKDhF/langeval-cli/lib/python3.11/site-packages (from langchain) (0.0.57)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/yangtao04/Library/Application Support/hatch/env/virtual/langeval-cli/4fLtKDhF/langeval-cli/lib/python3.11/site-packages (from langchain) (1.26.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/yangtao04/Library/Application Support/hatch/env/virtual/langeval-cli/4fLtKDhF/langeval-cli/lib/python3.11/site-packages (from langchain) (1.10.13)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/yangtao04/Library/Application Support/hatch/env/virtual/langeval-cli/4fLtKDhF/langeval-cli/lib/python3.11/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/yangtao04/Library/Application Support/hatch/env/virtual/langeval-cli/4fLtKDhF/langeval-cli/lib/python3.11/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: tqdm in /Users/yangtao04/Library/Application Support/hatch/env/virtual/langeval-cli/4fLtKDhF/langeval-cli/lib/python3.11/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/yangtao04/Library/Application Support/hatch/env/virtual/langeval-cli/4fLtKDhF/langeval-cli/lib/python3.11/site-packages (from tiktoken) (2023.10.3)\n",
      "Collecting transformers<5.0.0,>=4.6.0 (from sentence_transformers)\n",
      "  Downloading transformers-4.35.0-py3-none-any.whl.metadata (123 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.1/123.1 kB\u001b[0m \u001b[31m584.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch>=1.6.0 (from sentence_transformers)\n",
      "  Downloading torch-2.1.0-cp311-none-macosx_11_0_arm64.whl.metadata (24 kB)\n",
      "Collecting torchvision (from sentence_transformers)\n",
      "  Downloading torchvision-0.16.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting scikit-learn (from sentence_transformers)\n",
      "  Downloading scikit_learn-1.3.2-cp311-cp311-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Collecting scipy (from sentence_transformers)\n",
      "  Downloading scipy-1.11.3-cp311-cp311-macosx_12_0_arm64.whl.metadata (165 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.4/165.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nltk (from sentence_transformers)\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting sentencepiece (from sentence_transformers)\n",
      "  Downloading sentencepiece-0.1.99-cp311-cp311-macosx_11_0_arm64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.4.0 in /Users/yangtao04/Library/Application Support/hatch/env/virtual/langeval-cli/4fLtKDhF/langeval-cli/lib/python3.11/site-packages (from sentence_transformers) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/yangtao04/Library/Application Support/hatch/env/virtual/langeval-cli/4fLtKDhF/langeval-cli/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/yangtao04/Library/Application Support/hatch/env/virtual/langeval-cli/4fLtKDhF/langeval-cli/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.3.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/yangtao04/Library/Application Support/hatch/env/virtual/langeval-cli/4fLtKDhF/langeval-cli/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/yangtao04/Library/Application Support/hatch/env/virtual/langeval-cli/4fLtKDhF/langeval-cli/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/yangtao04/Library/Application Support/hatch/env/virtual/langeval-cli/4fLtKDhF/langeval-cli/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/yangtao04/Library/Application Support/hatch/env/virtual/langeval-cli/4fLtKDhF/langeval-cli/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/yangtao04/Library/Application Support/hatch/env/virtual/langeval-cli/4fLtKDhF/langeval-cli/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/yangtao04/Library/Application Support/hatch/env/virtual/langeval-cli/4fLtKDhF/langeval-cli/lib/python3.11/site-packages (from anyio<4.0->langchain) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/yangtao04/Library/Application Support/hatch/env/virtual/langeval-cli/4fLtKDhF/langeval-cli/lib/python3.11/site-packages (from anyio<4.0->langchain) (1.3.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/yangtao04/Library/Application Support/hatch/env/virtual/langeval-cli/4fLtKDhF/langeval-cli/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/yangtao04/Library/Application Support/hatch/env/virtual/langeval-cli/4fLtKDhF/langeval-cli/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: filelock in /Users/yangtao04/Library/Application Support/hatch/env/virtual/langeval-cli/4fLtKDhF/langeval-cli/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/yangtao04/Library/Application Support/hatch/env/virtual/langeval-cli/4fLtKDhF/langeval-cli/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/yangtao04/Library/Application Support/hatch/env/virtual/langeval-cli/4fLtKDhF/langeval-cli/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.8.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/yangtao04/Library/Application Support/hatch/env/virtual/langeval-cli/4fLtKDhF/langeval-cli/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/yangtao04/Library/Application Support/hatch/env/virtual/langeval-cli/4fLtKDhF/langeval-cli/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/yangtao04/Library/Application Support/hatch/env/virtual/langeval-cli/4fLtKDhF/langeval-cli/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yangtao04/Library/Application Support/hatch/env/virtual/langeval-cli/4fLtKDhF/langeval-cli/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Collecting sympy (from torch>=1.6.0->sentence_transformers)\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hCollecting networkx (from torch>=1.6.0->sentence_transformers)\n",
      "  Downloading networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: jinja2 in /Users/yangtao04/Library/Application Support/hatch/env/virtual/langeval-cli/4fLtKDhF/langeval-cli/lib/python3.11/site-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
      "Collecting tokenizers<0.15,>=0.14 (from transformers<5.0.0,>=4.6.0->sentence_transformers)\n",
      "  Downloading tokenizers-0.14.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.3.1 (from transformers<5.0.0,>=4.6.0->sentence_transformers)\n",
      "  Downloading safetensors-0.4.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: click in /Users/yangtao04/Library/Application Support/hatch/env/virtual/langeval-cli/4fLtKDhF/langeval-cli/lib/python3.11/site-packages (from nltk->sentence_transformers) (8.1.7)\n",
      "Collecting joblib (from nltk->sentence_transformers)\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn->sentence_transformers)\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision->sentence_transformers)\n",
      "  Downloading Pillow-10.1.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.5 kB)\n",
      "Collecting huggingface-hub>=0.4.0 (from sentence_transformers)\n",
      "  Downloading huggingface_hub-0.17.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/yangtao04/Library/Application Support/hatch/env/virtual/langeval-cli/4fLtKDhF/langeval-cli/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/yangtao04/Library/Application Support/hatch/env/virtual/langeval-cli/4fLtKDhF/langeval-cli/lib/python3.11/site-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.3)\n",
      "Collecting mpmath>=0.19 (from sympy->torch>=1.6.0->sentence_transformers)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.1.0-cp311-none-macosx_11_0_arm64.whl (59.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.35.0-py3-none-any.whl (7.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.3.2-cp311-cp311-macosx_12_0_arm64.whl (9.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading scipy-1.11.3-cp311-cp311-macosx_12_0_arm64.whl (29.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.7/29.7 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.16.0-cp311-cp311-macosx_11_0_arm64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Pillow-10.1.0-cp311-cp311-macosx_11_0_arm64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.0-cp311-cp311-macosx_11_0_arm64.whl (425 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.4/425.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Downloading tokenizers-0.14.1-cp311-cp311-macosx_11_0_arm64.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: sentence_transformers\n",
      "  Building wheel for sentence_transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=50c3493060cf8988f980ee74186ccafe9fd376e64c08ea00aa5bd5e8d430e93e\n",
      "  Stored in directory: /Users/yangtao04/Library/Caches/pip/wheels/ff/27/bf/ffba8b318b02d7f691a57084ee154e26ed24d012b0c7805881\n",
      "Successfully built sentence_transformers\n",
      "Installing collected packages: sentencepiece, mpmath, threadpoolctl, sympy, scipy, safetensors, pillow, networkx, joblib, torch, scikit-learn, nltk, huggingface-hub, torchvision, tokenizers, transformers, sentence_transformers\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.18.0\n",
      "    Uninstalling huggingface-hub-0.18.0:\n",
      "      Successfully uninstalled huggingface-hub-0.18.0\n",
      "Successfully installed huggingface-hub-0.17.3 joblib-1.3.2 mpmath-1.3.0 networkx-3.2.1 nltk-3.8.1 pillow-10.1.0 safetensors-0.4.0 scikit-learn-1.3.2 scipy-1.11.3 sentence_transformers-2.2.2 sentencepiece-0.1.99 sympy-1.12 threadpoolctl-3.2.0 tokenizers-0.14.1 torch-2.1.0 torchvision-0.16.0 transformers-4.35.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain openai faiss-cpu tiktoken sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "基于《跑跑卡丁车》与《泡泡堂》上所开发的游戏，由韩国Nexon开发与发行。中国大陆由盛大游戏运营，这是Nexon时隔6年再次授予盛大网络其游戏运营权。台湾由游戏橘子运营。玩家以水枪、小枪、锤子或是水炸弹泡封敌人(玩家或NPC)，即为一泡封，将水泡击破为一踢爆。若水泡未在时间内踢爆，则会从水泡中释放或被队友救援(即为一救援)。每次泡封会减少生命数，生命数耗完即算为踢爆。重生者在一定时间内为无敌状态，以踢爆数计分较多者获胜，规则因模式而有差异。以2V2、4V4随机配对的方式，玩家可依胜场数爬牌位(依序为原石、铜牌、银牌、金牌、白金、钻石、大师) ，可选择经典、热血、狙击等模式进行游戏。若游戏中离，则4分钟内不得进行配对(每次中离+4分钟)。开放时间为暑假或寒假期间内不定期开放，8人经典模式随机配对，采计分方式，活动时间内分数越多，终了时可依该名次获得奖励。\n",
      "{'id': 'TRIAL_800_QUERY_0'}\n",
      "256\n"
     ]
    }
   ],
   "source": [
    "# 正式项目中，应该以全部的数据作为我们的向量索引的基础数据，单条数据格式如上。我们挑选其中的 context 嵌入到向量索引中。\n",
    "# 本次我们就只以 test 的 1000 条数据建立索引。\n",
    "# Embedding 模型我们使用目前 cmteb reranking 任务 SOTA 的模型：[stella-base-zh](https://huggingface.co/infgrad/stella-base-zh)\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "\n",
    "# 从 cmrc 中提取 context\n",
    "texts_set = set()\n",
    "texts = []\n",
    "metadatas = []\n",
    "for i in cmrc[\"test\"]:\n",
    "    if i[\"context\"] not in texts_set:\n",
    "        # 去重\n",
    "        texts.append(i[\"context\"])\n",
    "        metadatas.append({\"id\": i[\"id\"]})\n",
    "        texts_set.add(i[\"context\"])\n",
    "print(texts[0])\n",
    "print(metadatas[0])\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init embedding\n",
    "embed = HuggingFaceEmbeddings(model_name=\"infgrad/stella-base-zh\")\n",
    "embed.embed_query(\"你好\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='牛佬，香港漫画家，原名文启明，1961年10月15日出生，生肖属牛，已婚无子女，少年时成长于蓝田廉租屋，中学二年级时辍学。12岁开始从事漫画行业，其时七十年代漫画行业百花齐放，「玉郎图书公司」、「小宝出版社」及「保光出版社」三分漫画天下，同期亦有漫画报纸《光报》、《喜报》、《青报》、《金报》、《生报》等，文氏也先后曾辗转加入过。13岁跟随漫画师父上官玉郎（莫君岳）学习，14岁成为上官小宝（邝东源）入室弟子，黄钧岳亦是牛佬入行的启蒙老师，到了八十年代初再加入玉郎机构，曾编绘《金刚》及为《如来神掌》起稿。1986年加入「邝氏」（八二画社），制作《爱情故事》，任《鬼书皇II我若为皇》编剧及监制，主编《江湖大佬》至1992年离开。在1992年4月1日与陈科琳、文鉴鸿、邱瑞新及伦裕国成立「浩一有限公司」，开始了其代表作《古惑仔》，之后自己成立现今的「和平出版有限公司」，其同父异母兄长文国兆Jacky亦帮手在「和平出版有限公司」处理行政工作。兴趣是烟不离手、游泳、养狗、潜水和写作，曾在年青时学习过中国武术，西洋拳、空手道、自由搏击及跆拳道，近年多在公司内操练泰拳，牛佬先后考获潜水Diver Master潜水长资格，及一级（基础）泰拳教练资格。歌手偶像是罗大佑、麦当娜及张学友，喜爱的电影导演则有徐克、黑泽明及史提芬·史匹堡，欣赏的漫画家则有永安巧及大友克洋。幼年时代邻居觉得其声线沉闷如牛，鼻大似牛，个性像牛，于是得「牛佬」称号。牛佬重视培育漫画人材，曾成立「牛家班」。伦裕国、邱瑞新、温日良、毕亦乐、胡达泉、颜子健及吴文辉都曾受到牛佬的指导。牛佬是香港漫画家中最多旗下漫画角色被拍成电影；亦是第一个旗下漫画被用作为电脑上线游戏的蓝本;更加是第一个推出三日刊的香港漫画家。', metadata={'id': 'TRIAL_920_QUERY_0'}),\n",
       " Document(page_content='《捉鬼男》（）美国一部由Tara Butters和Michele Fazekas创造的电视剧，首集是由Kevin Smith执导。Sam Oliver (Bret Harrison饰)Bert \"Sock\" Wysocki (饰)Benjamin \"Benji\" Gonzalez (饰)Andi Prendergast (饰)Josie Miller (饰)John Oliver (饰)魔鬼 (饰)Ted Gallagher (Donavon Stinson饰)第一次播放首集是在2007年7月27日，在圣地牙哥举办的Comic-Con International里。播出后不久，就获得很多评价家和观众好的反应。 这部电视剧在2007年9月25日在The CW电视台首播，每个星期二播放新的一集，不过到了2008年2月尾就被调到星期四，在超人前传(Smallville)之后。在美国编剧罢工结束后，\"\"\"\"捉鬼男\"\"\"\"被重新安排回到周二的播放时段。', metadata={'id': 'TRIAL_432_QUERY_0'}),\n",
       " Document(page_content='中国（南京）国际象棋超级大赛（Pearl Spring Super Tournament）原名中国（南京）国际象棋特级大师邀请赛，首届比赛于2008年12月11日至22日在南京市浦口区明发珍珠泉大酒店举行。本次大赛由南京市人民政府、国家体育总局棋牌运动管理中心主办，浦口区人民政府、南京市体育局承办，康缘药业股份有限公司、扬子晚报、蒙代尔国际企业家大学协办。被国际棋联定为21级赛事，也是亚洲迄今为止举办的最高水平的国际象棋大赛。双循环赛制比赛十轮，12月11日至15日进行前5轮，16日休息，17至21日进行后5轮。每方90分钟，每步棋加30秒。总奖金25万欧元，其中冠军8万欧元，第2至6名依次为5万5千欧元、4万欧元、3万欧元、2万5千欧元、2万欧元。结果托帕洛夫夺得冠军，阿罗尼扬获得亚军，卜祥志获得第三名。2009年2月1日被接纳为大满贯赛事并更名为中国（南京）国际象棋超级大赛。第二届比赛于2009年9月27日-10月9日举行。“康缘药业杯”2010中国(南京)国际象棋超级大赛于2010年10月19-30日举行', metadata={'id': 'TRIAL_798_QUERY_0'}),\n",
       " Document(page_content='林永康，()，香港个人资料私隐专员公署前副个人资料私隐专员，2005年9月离职。林永康大学毕业，获工商管理硕士学位，1996年加入公署，已婚，育有3名子女。2007年，林永康被控，涉嫌以权谋私、滥用职权、诈骗出差公干膳宿津贴、行使虚假证明文件及作虚假陈述，意图获取金钱利益。在2008年5月被裁定三项代理人使用文件意图欺骗主事人，及一项公职人员行为不当罪名成立，入囚九个月。 案情显示，林永康在澳洲墨尔本有自置住宅。辩方辩称，林永康从事资讯科技业界18年，热心公益，是次是出于疏忽，不是法官李瀚良指斥的贪心。不过，区域法院法官李瀚良指出，被告林永康身为行政部门首长，应该熟悉申领出差津贴的限额，却于2001至2003年期间多次乘公务之便赴澳洲墨尔本，留宿当地自置物业并且申领过高津贴。特别是，被告曾藉辞开会赴澳出席已被取消的会议，滥用职权从而谋取私利逾10万元，罪行非常严重。但考虑到被告在调查期间合作，加上已全数偿还署方损失，酌量减刑三个月，判被告入狱九个月。', metadata={'id': 'TRIAL_163_QUERY_0'})]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load to vectorstore\n",
    "vectorstore = FAISS.from_texts(\n",
    "    texts=texts,\n",
    "    embedding=embed,\n",
    "    metadatas=metadatas,\n",
    ")\n",
    "vectorstore.similarity_search(\"你好\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.save_local(\"cmrc-eval-zh.faiss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3 简单测试一下 RAG 检索效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "openai_api_key = getpass.getpass(\"Please input your openai api key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from operator import itemgetter\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"仅使用如下上下文回答问题：\n",
    "```\n",
    "{context}\n",
    "```\n",
    "\n",
    "问题：{question}\n",
    "回答：\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=openai_api_key)\n",
    "\n",
    "def _combine_documents(docs):\n",
    "    return \"\\n\\n\".join([i.page_content for i in docs])\n",
    "\n",
    "_inputs = RunnablePassthrough()\n",
    "\n",
    "retrieved_documents = {\n",
    "    \"docs\": itemgetter(\"question\") | retriever,\n",
    "    \"question\": itemgetter(\"question\"),\n",
    "}\n",
    "# Now we construct the inputs for the final prompt\n",
    "final_inputs = {\n",
    "    \"context\": lambda x: _combine_documents(x[\"docs\"]),\n",
    "    \"question\": itemgetter(\"question\"),\n",
    "}\n",
    "# And finally, we do the part that returns the answers\n",
    "answer = {\n",
    "    \"answer\": final_inputs | prompt | model,\n",
    "    \"docs\": itemgetter(\"docs\"),\n",
    "}\n",
    "\n",
    "final_chain = _inputs | retrieved_documents | answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "松平康忠什么时候被任命为知行？\n",
      "[Document(page_content='松平康忠（1546年－1618年9月28日）是日本战国时代至安土桃山时代的武将。长泽松平家第8代当主。德川氏的家臣。德川家康的从弟。父亲是松平政忠。母亲是松平清康的女儿碓井姬。正室是矢田姬（松平广忠的女儿，家康的妹妹）。继室是松平信定的女儿。通称源七郎、上野介。在天文15年（1546年）出生。父亲政忠在永禄3年（1560年）5月的桶狭间之战中被讨死，祖父亲广成为年幼的康忠的后见。另一方面，母亲碓井姬再嫁给德川家的重臣酒井忠次，于是与康忠分开。在永禄5年 （1562年）元服，被任命为三河国宝饭郡小坂井等1千8百10贯文的知行。康忠的叔父信重和近清等人亦被家康给予1百贯文并任命为辅佐。信重在翌年的三河一向一揆属于家康方被讨死，而近清一直辅助康忠直至天正16年（1588年）死去。此后康忠在元龟元年（1570年）从属于义父忠次参加姉川之战。接著在天正3年（1575年）的长筿之战中并跟随忠次参战。作为德川军的别働队攻略武田信实守备的鸢巢砦，成为帮助长筿城解围。之后成为家康的嫡男信康的家老，不过因为信康在天正7年（1579年）自杀而蛰居。后来得到家康的允许而复归，在天正10年（1582年）的本能寺之变发生后与家康一同穿越伊贺。之后参加天正12年（1584年）的小牧长久手之战。在天正16年（1588年）把家督让予嫡子康直并在京都隐居。不久，成为武藏深谷藩藩主的康直在文禄2年（1593年）以24歳之龄病死。已经隐居的康忠收家康的七男松千代为康直的养子并令其继承深谷藩1万石。不过松千代亦在庆长4年（1599年）死去，因此以松千代的哥哥辰千代（后来的松平忠辉）为继承人。在元和4年（1618年）8月10日死去。享年73岁。法号是源斋。在元和2年（1616年）因为忠辉被改易而令长泽松平家嫡流绝后，不过康忠的血脉亦有存续到后世。在天文9年（1540年）的安城合战中战死的同名武将松平康忠（甚六郎）是松平宗家亲忠系的松平张忠的儿子，不是同一人。', metadata={'id': 'TRIAL_598_QUERY_0'}), Document(page_content='折上原之战（），在日本战国时代的1589年7月17日发生，是伊达政宗对芦名义广和佐竹义重的一场战役。人取桥之战后，伊达政宗与芦名氏和佐竹氏对立表面化，而伊达在仙道筋（即现在的福岛县中）的势力越来越大，芦名氏及佐竹氏都对此感到重大危机。后来伊达政宗违反丰臣秀吉所定的惣无事令（即停战命令），开始夺取芦名氏的据点。伊达政宗为确保从自家到敌军要塞的道路和猪苗代城的据点，拉拢了猪苗代盛国（盛国的长子猪苗代盛胤是芦名军的先锋，盛国与再婚的妻子所生的次子猪苗代宗国是伊达军）。另一方面，芦名义广率领部队从须贺川城出发，往猪苗代湖南岸出发，集结在黑川城。在高森山布阵的芦名氏向伊达势力挑衅，在平民家放火。那时伊达军兵力为21,000人，芦名军兵力为18,000，两者不相伯仲。但自1580年芦名盛氏去世后，继任当主芦名盛隆就因卷入家中纠纷而被暗杀身亡，次任当主芦名义广虽受家臣金上盛备的拥护，但也无法有效统率家中势力，加上有伊达军的内应，芦名军可谓欠缺团结力。战事在猪苗代湖北岸展开，开战初期来自西的烈风变成顺风，加上芦名军的先锋富田隆实十分活跃，对芦名军十分有利。但当风向转为东风后，伊达军的形势开始渐入佳境，芦名四天王之一的富田氏实先行撤退、引发其他友军傍观及部分家臣相继离反、金上盛备与四天王的佐濑种常・常雄戦死后，芦名军全面崩溃。战败的芦名军本来由日桥川逃走，但中途被黑川城妨碍前进，令兵力损害更大。芦名义广带仅存家臣逃离战场，大绳义辰及二本松义纲一行也在6月10日的夜晚逃往佐竹氏的常陆国。芦名氏的战力因有力家臣金上盛备和佐濑种常等人的战死而受到重大打击。而家督芦名义广因家臣无心应战及奥州的惣无事令而没有再次出战，逃往佐竹家的常陆国。伊达政宗则成为南奥州的霸者，把居城迁到黑川城，并把白川结城的石川氏臣服于伊达氏。但翌年因丰臣秀吉推行奥州仕置政策及以违反惣无事令为由，没收了会津。可是丰臣秀吉并没有把会津归还给芦名氏，反而给了蒲生氏乡。日本战争列表', metadata={'id': 'TRIAL_582_QUERY_0'}), Document(page_content='阿部重次（、庆长3年（1598年） - 庆安4年4月20日（1651年6月8日）），武藏国岩槻藩第2代藩主。德川家光时代就任老中。阿部家宗家2代。大坂城代、初代藩主·阿部正次的次男。母亲是佐原义成之女。正室是三浦重成之女、继室是松平定胜之女正寿院。子女有阿部定高（长男）、阿部正春（次男）、女儿（松平忠倶正室）、女儿（松平近陈正室）。官位是山城守、对马守。起初是舅舅·三浦重成（义次）的养子，在哥哥阿部政澄死后，回到阿部家。和同时期担任老中的阿部忠秋是堂兄弟，重次属于本家。主君家光去日光东照宫参拜时，从江户到岩槻住了一天，岩槻城主重次接待了他。庆安4年（1651年），随家光的去世而殉死。家督由长男·定高继承。辞世辞是。', metadata={'id': 'TRIAL_852_QUERY_0'}), Document(page_content='渡川之战，又名四万十川之战，发生于天正3年（1575年）。是长宗我部元亲统一土佐的关键战役。一条兼定带着3500人攻打长宗我部元亲，原本预期农忙期间长宗我部元亲无法派出大量军队出战，但由于长宗我部元亲在领内实行「一领具足」制度，因此集结约7300名士兵，在渡川迎击，长宗我部元亲将军队分成2股，一部直接渡河，一部由福留仪重率军迂回至北方，后来一条兼定受到长宗我部元亲的挑拨，被长宗我部元亲的铁炮队攻击，又担心被长宗我部元亲两面夹击而后退，元亲见状便命令全军渡河突击，一条军溃败，战死200余人。此战奠定了长宗我部元亲在土佐的霸权。此战后，兼定逃往濑户内隐遁生活，10年后43岁时死去。', metadata={'id': 'TRIAL_555_QUERY_0'})]\n",
      "{'answer': AIMessage(content='松平康忠在永禄5年（1562年）被任命为知行。'), 'docs': [Document(page_content='松平康忠（1546年－1618年9月28日）是日本战国时代至安土桃山时代的武将。长泽松平家第8代当主。德川氏的家臣。德川家康的从弟。父亲是松平政忠。母亲是松平清康的女儿碓井姬。正室是矢田姬（松平广忠的女儿，家康的妹妹）。继室是松平信定的女儿。通称源七郎、上野介。在天文15年（1546年）出生。父亲政忠在永禄3年（1560年）5月的桶狭间之战中被讨死，祖父亲广成为年幼的康忠的后见。另一方面，母亲碓井姬再嫁给德川家的重臣酒井忠次，于是与康忠分开。在永禄5年 （1562年）元服，被任命为三河国宝饭郡小坂井等1千8百10贯文的知行。康忠的叔父信重和近清等人亦被家康给予1百贯文并任命为辅佐。信重在翌年的三河一向一揆属于家康方被讨死，而近清一直辅助康忠直至天正16年（1588年）死去。此后康忠在元龟元年（1570年）从属于义父忠次参加姉川之战。接著在天正3年（1575年）的长筿之战中并跟随忠次参战。作为德川军的别働队攻略武田信实守备的鸢巢砦，成为帮助长筿城解围。之后成为家康的嫡男信康的家老，不过因为信康在天正7年（1579年）自杀而蛰居。后来得到家康的允许而复归，在天正10年（1582年）的本能寺之变发生后与家康一同穿越伊贺。之后参加天正12年（1584年）的小牧长久手之战。在天正16年（1588年）把家督让予嫡子康直并在京都隐居。不久，成为武藏深谷藩藩主的康直在文禄2年（1593年）以24歳之龄病死。已经隐居的康忠收家康的七男松千代为康直的养子并令其继承深谷藩1万石。不过松千代亦在庆长4年（1599年）死去，因此以松千代的哥哥辰千代（后来的松平忠辉）为继承人。在元和4年（1618年）8月10日死去。享年73岁。法号是源斋。在元和2年（1616年）因为忠辉被改易而令长泽松平家嫡流绝后，不过康忠的血脉亦有存续到后世。在天文9年（1540年）的安城合战中战死的同名武将松平康忠（甚六郎）是松平宗家亲忠系的松平张忠的儿子，不是同一人。', metadata={'id': 'TRIAL_598_QUERY_0'}), Document(page_content='折上原之战（），在日本战国时代的1589年7月17日发生，是伊达政宗对芦名义广和佐竹义重的一场战役。人取桥之战后，伊达政宗与芦名氏和佐竹氏对立表面化，而伊达在仙道筋（即现在的福岛县中）的势力越来越大，芦名氏及佐竹氏都对此感到重大危机。后来伊达政宗违反丰臣秀吉所定的惣无事令（即停战命令），开始夺取芦名氏的据点。伊达政宗为确保从自家到敌军要塞的道路和猪苗代城的据点，拉拢了猪苗代盛国（盛国的长子猪苗代盛胤是芦名军的先锋，盛国与再婚的妻子所生的次子猪苗代宗国是伊达军）。另一方面，芦名义广率领部队从须贺川城出发，往猪苗代湖南岸出发，集结在黑川城。在高森山布阵的芦名氏向伊达势力挑衅，在平民家放火。那时伊达军兵力为21,000人，芦名军兵力为18,000，两者不相伯仲。但自1580年芦名盛氏去世后，继任当主芦名盛隆就因卷入家中纠纷而被暗杀身亡，次任当主芦名义广虽受家臣金上盛备的拥护，但也无法有效统率家中势力，加上有伊达军的内应，芦名军可谓欠缺团结力。战事在猪苗代湖北岸展开，开战初期来自西的烈风变成顺风，加上芦名军的先锋富田隆实十分活跃，对芦名军十分有利。但当风向转为东风后，伊达军的形势开始渐入佳境，芦名四天王之一的富田氏实先行撤退、引发其他友军傍观及部分家臣相继离反、金上盛备与四天王的佐濑种常・常雄戦死后，芦名军全面崩溃。战败的芦名军本来由日桥川逃走，但中途被黑川城妨碍前进，令兵力损害更大。芦名义广带仅存家臣逃离战场，大绳义辰及二本松义纲一行也在6月10日的夜晚逃往佐竹氏的常陆国。芦名氏的战力因有力家臣金上盛备和佐濑种常等人的战死而受到重大打击。而家督芦名义广因家臣无心应战及奥州的惣无事令而没有再次出战，逃往佐竹家的常陆国。伊达政宗则成为南奥州的霸者，把居城迁到黑川城，并把白川结城的石川氏臣服于伊达氏。但翌年因丰臣秀吉推行奥州仕置政策及以违反惣无事令为由，没收了会津。可是丰臣秀吉并没有把会津归还给芦名氏，反而给了蒲生氏乡。日本战争列表', metadata={'id': 'TRIAL_582_QUERY_0'}), Document(page_content='阿部重次（、庆长3年（1598年） - 庆安4年4月20日（1651年6月8日）），武藏国岩槻藩第2代藩主。德川家光时代就任老中。阿部家宗家2代。大坂城代、初代藩主·阿部正次的次男。母亲是佐原义成之女。正室是三浦重成之女、继室是松平定胜之女正寿院。子女有阿部定高（长男）、阿部正春（次男）、女儿（松平忠倶正室）、女儿（松平近陈正室）。官位是山城守、对马守。起初是舅舅·三浦重成（义次）的养子，在哥哥阿部政澄死后，回到阿部家。和同时期担任老中的阿部忠秋是堂兄弟，重次属于本家。主君家光去日光东照宫参拜时，从江户到岩槻住了一天，岩槻城主重次接待了他。庆安4年（1651年），随家光的去世而殉死。家督由长男·定高继承。辞世辞是。', metadata={'id': 'TRIAL_852_QUERY_0'}), Document(page_content='渡川之战，又名四万十川之战，发生于天正3年（1575年）。是长宗我部元亲统一土佐的关键战役。一条兼定带着3500人攻打长宗我部元亲，原本预期农忙期间长宗我部元亲无法派出大量军队出战，但由于长宗我部元亲在领内实行「一领具足」制度，因此集结约7300名士兵，在渡川迎击，长宗我部元亲将军队分成2股，一部直接渡河，一部由福留仪重率军迂回至北方，后来一条兼定受到长宗我部元亲的挑拨，被长宗我部元亲的铁炮队攻击，又担心被长宗我部元亲两面夹击而后退，元亲见状便命令全军渡河突击，一条军溃败，战死200余人。此战奠定了长宗我部元亲在土佐的霸权。此战后，兼定逃往濑户内隐遁生活，10年后43岁时死去。', metadata={'id': 'TRIAL_555_QUERY_0'})]}\n",
      "永禄5年 （1562年）\n"
     ]
    }
   ],
   "source": [
    "index = 10\n",
    "q = cmrc[\"test\"][index][\"question\"]\n",
    "print(q)\n",
    "print(final_chain.invoke({\"question\": q}))\n",
    "print(cmrc[\"test\"][index][\"answers\"][\"text\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 使用 LLM 标注数据集\n",
    "\n",
    "TODO，参考 https://docs.llamaindex.ai/en/stable/examples/evaluation/QuestionGeneration.html\n",
    "\n",
    "主要方法是先拆分 context，然后对每段 context 使用 LLM 抽取 QA 对，从而形成数据集。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Embedding 模型评估和微调\n",
    "\n",
    "可以使用 c-mteb 中 Reranking 方法评估检索模型的效果。仅需要 question 和 context ，负面样本可以自动生成。评估如果性能不佳，可以引入微调方案。\n",
    "\n",
    "具体参见 [c-mteb](c-mteb/c-mteb.md)，但是这种方法只能评估 Embedding 模型，如果你的检索是混合检索（比如混合了 BM25 + Embedding + Rerank），那么就无法通过这种方法评估检索效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 运行 + 评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provider 为 rag.py，会继承当前 shell 的环境变量\n",
    "# 执行 eval\n",
    "!OPENAI_API_KEY=\"xxxx\" langeval -v run cmrc-eval-zh.yaml --sample\n",
    "\n",
    "# 执行批量的 eval\n",
    "# export OPENAI_API_KEY = \"\"\n",
    "# langeval run cmrc-eval-zh.yaml\n",
    "\n",
    "# 实现了 生成正确率和检索召回率的计算，具体指标请参考文档。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langeval-cli",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
